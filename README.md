# Real-Time Stock Market Data Analysis with Apache Kafka and AWS
 ## Introduction
 
In this project, I developed an End-To-End Data Engineering pipeline for analyzing IPL (Indian Premier League) data using Apache Spark and Databricks. The project leverages the power of cloud computing with Amazon S3 for data storage, Databricks for scalable data processing, and Python libraries like Matplotlib and Seaborn for data visualization. The pipeline processes IPL data, stores it in Amazon S3, transforms it using Apache Spark, and then analyzes it with SQL queries and visualizations.

## Architecture
![Architecture](https://github.com/user-attachments/assets/ef8261ba-2ba7-4ab3-b0f6-6bea32115d73)

## Technology Used

- **Apache Spark**:  Data processing and transformation.
- **Databricks**: Cloud-based platform for running Apache Spark jobs.
- **Amazon S3**: Storage solution for structured IPL data.
- **Python**: Data analysis and visualization.
  - **Matplotlib**: Visualization library.
  - **Seaborn**: Seaborn: Statistical data visualization library.

## Prerequisites

To run this project, you'll need:

    - An AWS account with access to S3.
    - A Databricks account for creating clusters and running Spark jobs.
    - Basic knowledge of Apache Spark, SQL, and Python.

## Dataset Used

The IPL dataset can be found at the following URL: https://data.world/raghu543/ipl-data-till-2017

## Conclusion

This project demonstrates the capabilities of Apache Spark combined with Databricks for scalable data processing and analysis. By leveraging cloud infrastructure and powerful data processing frameworks, complex data challenges like IPL data analysis can be handled with ease, making it a crucial skill set for growth in the data field.
